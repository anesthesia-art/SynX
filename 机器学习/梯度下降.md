## 平方和损失函数
我觉得就像高中数学里的残差平方和，数据越小就表示拟合程度越高，在机器学习中作用差不多，函数值越小，代表拟合越精确
## 梯度下降
最快的下山路径，学习率相当于一步的步长
## 一元线性函数y=wx+b 对平方和损失函数 L(w)的梯度下降权重更新公式。
>w:=w + α * (y_i - (w * x_i + b)) * x_i
> 
> b:=b + α * (y_i - (w * x_i + b))

AI搜的
## 学习率
过大可能会导致拟合值一直徘徊或者越走越远，过小可能会导致在给定的迭代次数内，拟合达不到想要的精度
## 梯度下降和随机梯度下降
每次梯度下降之前会考量全部数据，计算全部数据后得出下降梯度，绝对正确，但是速度慢
随机梯度下降之前仅考量一个数据，更快捷，但可能是错的
## mini_batch梯度下降
mini_batch梯度下降会考量一小批数据，属于梯度下降和随机梯度下降的折中

没有找到什么关于梯度下降的学习视频，十分有七八分的不懂
